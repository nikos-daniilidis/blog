<!DOCTYPE html>

<script type="text/javascript"
	src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Map/Reduce: 21st century Lemmings</title>
    <meta name="description" content="A blog about science, technology, society, and everything in-between.
">

    <link rel="stylesheet" href="/css/main.css">
    <link rel="canonical" href="http://yourdomain.com/jekyll/update/2014/10/13/Map-Reduce:-21st-century-Lemmings.html">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Nikos Daniilidis</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
          <a class="page-link" href="/publications/index.html">Publications</a>
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Map/Reduce: 21st century Lemmings</h1>
    <p class="post-meta">Oct 13, 2014</p>
  </header>

  <article class="post-content">
    <p>A while ago I started learning and setting up small-scale programming jobs on Hadoop/MapReduce. My first 
reaction to the new tools was “Wow, this is empowering!”. For the first time since I got into the business of 
machine learning and data science, I felt I could reach things beyond the capabilities of my desktop PC. At 
the same time, my overall feeling in going through the logic of the Map Reduce framework, was a déjà vu from 
my teenage years, when a  friend and I would play <a href="http://en.wikipedia.org/wiki/Lemmings_%28video_game%29">Lemmings</a> 
on his Atari for hours: You are given an army of small, dumb workers. Get them to work together the right way, 
and you are guaranteed to have awesome results and fun along the way. In this spirit, this will be the first of a number of posts on MapReduce.</p>

<p>As a general reminder, a Map/Reduce process consists of two parts. In the first part, a number of so-called “mappers” 
go through the data and produce <code>key,value</code> pairs. The mappers can each go through a different chunk of the data, so 
that they work in parallel. These pairs are then sorted on the keys, partitioned into new chunks, and passed to the 
reducers (note, however, that an additional “combiner” stage can be added after the mappers’ job is done, e.g. to 
alleviate network traffic on a computer cluster). The reducers do some additional analysis on the <code>key,value</code> pairs 
(for example count how many different values appear for each key), and produce a final result which should normally 
be human-readable.</p>

<p>For example, imagine you have two decks of cards which are mixed together, and want to find out if any cards are 
misssing from one of the decks. One basic check is to go through the decks, and see if there are four cards for each 
figure and for each deck. To do this, you split the mixed-up deck in two and give one half to each of your two kids 
(the mappers). You tell them to go through the cards, and for each card write on a little note the type of figure 
and which deck it came from (the <em>key</em>). In this particular example it does not matter what you pass as a <em>value</em>, 
so the value can be blank (say null). At the end you have a large number of little papers saying <em>(Ace Deck 1, null)</em>, 
<em>(Eight Deck 2, null)</em>, ans so on. The next step is to sort the little pieces of paper, according to the figure value 
on them (e.g. <em>Ace</em>, <em>Two</em>, <em>Three</em>, etc.), followed by the deck value on them (i.e. all of the notes on <em>Deck 1</em> come before 
the  papers from <em>Deck 2</em>). After this  is done, you split the stack of sorted paper notes in two. You take one half, 
and your spouse the other half. Now you two are the reducers: you each go through your stack of notes, and keep a 
register for each figure and deck. In other words, you record how many notes you saw saying <em>(Aces Deck 1, null)</em>, 
<em>(Eight Deck 2, null)</em>, and so on. Because of the sorting, you will see all the notes about Aces from <em>Deck 1</em> before 
you see any other note, so as soon as you see a Two from <em>Deck 1</em>, you can write down how many Aces from <em>Deck 1</em> you saw. 
If you end up with a three, you know one ace is missing from deck one, and you can note  this on a different piece of 
paper. The exact same thing holds for your spouse. In the end you can put your summary notes down to see how many 
figures of each kind are missing from each deck, and that’s all there is. This is an example of solving a counting problem 
using Map/Reduce. Of course, in a real implementation there are several kinds of issues having to do with the fact that 
the machines doing the work are on a  cluster with certain communication constrains between the machines, and with some 
of the machines occasionally failing, but I will not go into this. </p>

<p>I will not cover in detail how the Map/Reduce framework solves different kinds of problems. If you are  interested in a 
basic introduction, the Udacity course videos are excellent. Instead of repeating that material, I will show how the 
framework solves a particular kind of problem: creating an inverted index of words appearing on an online forum. The data 
I will work on is from the Udacity forum, and you can find the complete set <a href="http://content.udacity-data.com/course/hadoop/forum_data.tar.gz">here</a>. 
This forum is similar to the Stack Exchange websites, and was built using <a href="http://www.osqa.net/">OSQA</a>. Each post in 
the forum is a node which contains the text of the post, information about the author, the parent node for answer and 
comment posts, etc. My goal is to go through all the posts in the forum, and for each word, list all of the nodes on which 
the word appears. However, I want to be able to show the data as it is being processed, so I will work on a subset of the 
full forum data, which I can easily inspect on my text editor. You can find the input data <a href="https://github.com/nikos-daniilidis/hadoop-mapreduce-o">here</a>, 
under the name <code>testfile-forum</code>. </p>

<p>To solve the problem using Map/Reduce, we will need to break it into two tasks. First we will process the raw data and output 
a series of <code>key,value</code> pairs (this is the mappers’ job). Since we want to find the nodes in which a certain word appears, 
we will use the words as keys and the values will be node ids. The pseudocode for the task looks something like the following</p>

<pre><code>    for each entry in forum
        find the entry text
        find the node id
        split the entry text into words
        for each word in the entry text
            print word, node id
</code></pre>

<p>In python, this looks as follows:
import sys, csv</p>

<pre><code>	reader = csv.reader(sys.stdin, delimiter='\t')
	noNoList = ['.',',','!','?',':',';','\"','(',')','&lt;','&gt;','[',']','#','$','=','-','/']
	
	for line in reader:
		if line[0]=="id":
			continue
		elif len(line) == 19:
			nodeid = line[0]
			body = line[4]
		for ch in noNoList:
			body = body.replace(ch," ")
		body = body.replace("  "," ")
		wordlist = body.lower().split(" ")
		for word in wordlist:
			print "{0}\t{1}".format(word, nodeid)
</code></pre>

<p>You can find this as <code>mapper9.py</code> <a href="https://github.com/nikos-daniilidis/hadoop-mapreduce-o">here</a>. If you convert this python script 
to an executable file (using <code>chmod +x mapper9.py</code>), you can simulate the action of the map and sort by streaming the contents of 
the test file to the mapper, and sorting the output of the mapper (on a terminal this is done using <code>cat | ./mapper9.py | sort</code>). 
The output is pretty long, and there are a lot of “non-word” items, since  I did not make any particular effort to clean up the text 
in the mapper function. Here is a section of the output which should make the next step obvious:</p>

<pre><code>	any	2741
	any	7185
	application	26454
	are	2312
	as	2312
	as	2312
	audio	2312
	be	2312
	be	6361
	being	2741
</code></pre>

<p>You can see that sorting the output of the mapper makes the life of the reducers much easier. They can be very dumb programs, using 
limited resources. If a reducer is given this segment of the mapper output, all that is needed is for it to make a list of all the 
indices, as long as the key is the same. When the key changes, it can dump the key and list of node ids to the putput, and start over 
with the next key. In Python, this looks as follows: </p>

<pre><code>	import sys, string

	oldKey = None
	nodeList = []
	listSeparator = ", "

	for line in sys.stdin:
		data_mapped = line.strip().split("\t")
		if len(data_mapped) != 2:
			# Something has gone wrong. Skip this line.
			continue

		thisKey, thisNode = data_mapped

		if oldKey and oldKey != thisKey:
			nodeList.sort()
			numNodes = len(nodeList)
			nodeStr = string.join(nodeList,listSeparator)
			print "{0}\t{1}\tTotal\t{2}".format(oldKey,nodeStr,str(numNodes))
			oldKey = thisKey; # reduntant but whatever
			nodeList = []        

		oldKey = thisKey
		nodeList.append(thisNode.strip('\"'))

	if oldKey != None:
		nodeList.sort()
		numNodes = len(nodeList)
		nodeStr = string.join(nodeList,listSeparator)
		print "{0}\t{1}\tTotal\t{2}".format(oldKey,nodeStr,str(numNodes))
</code></pre>

<p>When we feed the sorted output of the mapper to this function (using <code>cat | ./mapper9.py | sort | ./reducer9.py</code>), the result is, again, 
a long file. The section of the file pertaining to the section of mapper output we saw above, is here:</p>

<pre><code>	any	2741, 7185	Total	2
	application	26454	Total	1
	are	2312	Total	1
	as	2312, 2312	Total	2
	audio	2312	Total	1
	be	2312, 6361	Total	2
	being	2741	Total	1
</code></pre>

<p>And that is all. As you can see, in this particular example I have asked the reducer to do a little bit more work and tell me how many 
times each word has appeared, but the essence doesn’t change. </p>

<h3 id="the-caveat">The caveat</h3>

<p>I chose here two examples which are easy to follow through, but could give an oversimplified immpression of the actual issues in using the MapReduce framework. The types of problems I described above(counting and creating inverted index), are relatively easy, in that they do not tax the computer cluster with too much communication between the different machines carrying out individual map tasks. As an example of a situation which is more complicated, consider any algorithm which involves matrix multiplication, e.g. the matrix multiplication common in algorithms for calculating the page rank of web pages (see excellent discussion <a href="http://www.mmds.org/">here</a>). In such cases, relatively efficient solutions exist within the MapReduce framework (by subdividing the matrices to small blocks which are processed in parallel). However, there  exist problems (matrix inversion) for which -to my knowledge- efficient implementations are still under way.  <a href="http://oligotropos.wordpress.com/2014/10/13/mapreduce-lemmings-in-the-21st-century/">Same post on wordpress</a>.</p>


  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Nikos Daniilidis</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li><a href="mailto:nikos.daniilidis@gmail.com">nikos.daniilidis@gmail.com</a></li>
          
          <li><a href="https://www.linkedin.com/in/ndaniilidis">https://www.linkedin.com/in/ndaniilidis</a></li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/nikos-daniilidis">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">nikos-daniilidis</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://twitter.com/ndaniilidis">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">ndaniilidis</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text">A blog about science, technology, society, and everything in-between.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
